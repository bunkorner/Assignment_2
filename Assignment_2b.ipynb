{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bunkorner/VR_Assignment2/blob/main/Assignment_2b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nFQgbIqmgEcz"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwt-JH1_j2KA",
        "outputId": "db1c86bf-04ae-4e97-fa5a-eb1086b14eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "srcPath = '/content/gdrive/MyDrive/CV/Assignment_2/Assignment2_BikeHorses'\n",
        "destPath = '/content/gdrive/MyDrive/CV/Assignment_2/Bike_Horse'"
      ],
      "metadata": {
        "id": "Pc0xJwjvIU9v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Organized the Dataset, which previously had IMG1_(Copy).jpg is now IMG1.jpg, IMG2.jpg and so on."
      ],
      "metadata": {
        "id": "U2wD8gYNBy1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking all the images from Source Path and making an organized copy in Destination Path"
      ],
      "metadata": {
        "id": "IHALIZ4dCRR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(destPath):\n",
        "    os.mkdir(destPath)"
      ],
      "metadata": {
        "id": "UbD1_dErIb0i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onlyDirs = [f for f in os.listdir(srcPath) if os.path.isdir(os.path.join(srcPath, f))]\n",
        "\n",
        "for directory in onlyDirs:\n",
        "    rdPath = srcPath+'/'+directory\n",
        "    path = destPath+'/'+directory\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "        \n",
        "    onlyfiles = [f for f in os.listdir(rdPath) if os.path.isfile(os.path.join(rdPath, f))]\n",
        "    i=0\n",
        "    for file in onlyfiles:\n",
        "        i = i + 1\n",
        "        imgPath = rdPath+'/'+file\n",
        "        img = cv2.imread(imgPath)\n",
        "        wrtPath = path+'/' + str(i) + '.jpg'\n",
        "        cv2.imwrite(wrtPath,img)"
      ],
      "metadata": {
        "id": "YVs_mB1eEzxr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imgs will store the Path along with Name of all the images."
      ],
      "metadata": {
        "id": "_HXzqWXvCiwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labels will store the Ground Truth for the respective image."
      ],
      "metadata": {
        "id": "KcP36zZwCryl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = []\n",
        "labels = []\n",
        "label = -1\n",
        "\n",
        "dirs = [f for f in os.listdir(destPath) if os.path.isdir(os.path.join(destPath, f))]\n",
        "\n",
        "for directory in dirs:\n",
        "    label = label + 1\n",
        "    path = destPath+'/'+directory\n",
        "    files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
        "\n",
        "    for file in files:\n",
        "        imgPath = path+'/'+file\n",
        "        imgs.append(imgPath)\n",
        "        labels.append(label)"
      ],
      "metadata": {
        "id": "f_Fw4xhLJ0Y2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(imgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNHovquiJ4du",
        "outputId": "1cbb0aca-0139-4d97-bf93-368c243159ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "188"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 188 images in total."
      ],
      "metadata": {
        "id": "3srq_Pl7Cyrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgFiles = []\n",
        "for imgName in imgs:\n",
        "    img = cv2.imread(imgName)\n",
        "    imgFiles.append(img)\n",
        "imgFiles = np.asarray(imgFiles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkUJbnR8J6PU",
        "outputId": "b0a0c7c0-c159-4351-cce8-d446326dc113"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-eb5b51ae2ef9>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  imgFiles = np.asarray(imgFiles)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImgFiles will contain all the data of images stacked one over other."
      ],
      "metadata": {
        "id": "6DkDYUuaC3w6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "numberOfClusters=300"
      ],
      "metadata": {
        "id": "4TAMHtwGKShL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have kept K = 300 here, that is there will be 300 unique visual words."
      ],
      "metadata": {
        "id": "CnDIXKALDHnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "descriptors = np.asarray([])\n",
        "ext = cv2.SIFT_create()\n",
        "for img in imgFiles:\n",
        "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "    keypoints, desc = ext.detectAndCompute(gray, None)\n",
        "    if type(desc) == np.ndarray :\n",
        "        if descriptors.shape[0] == 0:\n",
        "            descriptors = desc\n",
        "        else:\n",
        "            descriptors = np.concatenate((descriptors, desc), axis=0)\n",
        "kmeans = KMeans(n_clusters = numberOfClusters)"
      ],
      "metadata": {
        "id": "LIYYkhAmKNO6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using SIFT to extract features from all the image."
      ],
      "metadata": {
        "id": "zoGYXlMTDaMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, those extracted features in terms of patches is fed to KMeans algorithm."
      ],
      "metadata": {
        "id": "8aIfTa-LDg8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "descriptors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMxd37Bkzmg5",
        "outputId": "74e4d890-ca62-445a-e78e-cfd6824663d2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178044, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can see there are 178044 different features obtained from 188 images, these features will have many repeating (similar) features such as wheels, Face of the horse and so on, which will be then considered as a single word."
      ],
      "metadata": {
        "id": "CPW8RcLjDudy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans.fit(descriptors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOmIGQFaKZoW",
        "outputId": "3085ce3f-4597-4dca-86ba-50711fb8a119"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=300)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now all the features are divided into 300 clusters."
      ],
      "metadata": {
        "id": "HR56har_ELH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "allBOVW = []\n",
        "ext = cv2.xfeatures2d.SIFT_create()\n",
        "for img in imgFiles:\n",
        "  bovw = [0]*numberOfClusters\n",
        "  gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "  keypoints, descriptors = ext.detectAndCompute(gray, None)\n",
        "  if type(descriptors) == np.ndarray:\n",
        "      pred = kmeans.predict(descriptors)\n",
        "      for ele in pred:\n",
        "          bovw[ele] = bovw[ele] + 1\n",
        "  allBOVW.append(bovw)"
      ],
      "metadata": {
        "id": "j-fVieq8KdWk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we have a new image, we again extract its features and descriptors using SIFT, then feed this as input to our now trained KMeans model, then with the predicted word we'll create a histogram (named bovw, here)."
      ],
      "metadata": {
        "id": "kNxX8pGfEYVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This histogram will now be useful as Train_X and Labels as our Train_Y."
      ],
      "metadata": {
        "id": "J7VIOr9wFFfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this piece of code, we find the histogram for all the images (i.e. entire ImgFiles array)"
      ],
      "metadata": {
        "id": "FUHNGWP0FS5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "allBOVW = np.asarray(allBOVW)"
      ],
      "metadata": {
        "id": "6Jcc1CP0Nxeg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "cdwa2l3gOwyS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we split the data into Training and Testing data, to know how our models performed"
      ],
      "metadata": {
        "id": "jOoRN0rxFhAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainImgs,testImgs, trainLabels, testLabels = train_test_split(allBOVW, labels, train_size=0.7, random_state=0)"
      ],
      "metadata": {
        "id": "Datvupy7Ogur"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainImgs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKmk-d1jIPGN",
        "outputId": "9f9fb4e8-946c-46ca-99fd-f52fa8883d16"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  0,  1, ...,  1,  2,  1],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 5,  0, 16, ...,  5,  5,  1],\n",
              "       ...,\n",
              "       [ 1,  0,  6, ...,  0,  2,  3],\n",
              "       [ 2,  0,  2, ...,  3,  4,  6],\n",
              "       [ 0,  0,  3, ...,  3,  3,  2]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Logistic Regression"
      ],
      "metadata": {
        "id": "gaMqRfs7F-vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LRegression = LogisticRegression().fit(trainImgs, trainLabels)"
      ],
      "metadata": {
        "id": "G_i1Q5TpFyFm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRegression.score(testImgs,testLabels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lS6BKHfF4AP",
        "outputId": "bacc747f-b2cc-40b4-e2d9-f42ba650f77e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9649122807017544"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Support Vector Classifier"
      ],
      "metadata": {
        "id": "-lTLflwKGCyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "SVClassifier = svm.SVC(gamma=0.01,kernel='linear')\n",
        "SVClassifier.fit(trainImgs,trainLabels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQjdO-H9PESd",
        "outputId": "f4f964fc-ad29-4b40-9b1d-53d6a0003363"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(gamma=0.01, kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SVClassifier.score(testImgs,testLabels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V63J2H8JPXo_",
        "outputId": "a24efb25-5c33-484b-cc6f-0138401bb19f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9649122807017544"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tried running the same Code but instead of using SIFT, I tried SURF and ORB, the code took less time to execute but there was no loss in Accuracy as such."
      ],
      "metadata": {
        "id": "5XAiYIB2GUX4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DcrdUBT_GoXm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XUwc2aOMhl4q1H9i145p_QU_XsPnYyou",
      "authorship_tag": "ABX9TyPeHA/Nrj7ZCcsxMtXJW47N",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}